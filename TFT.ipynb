{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f4c610-f2a7-40bb-8eed-dc546691c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS & CONFIG\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "@dataclass\n",
    "class TFTConfig:\n",
    "    n_past_games: int = 5               # encoder length\n",
    "    batch_size: int = 64\n",
    "    hidden_size: int = 64\n",
    "    num_heads: int = 2          # heads so 32 dimension per head\n",
    "    dropout: float = 0.1\n",
    "    n_epochs: int = 20\n",
    "    lr: float = 1e-3\n",
    "    #weight_decay: float = 1e-2 # L2 Regularization for smoothness\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA LOADING & FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "\n",
    "static_categoricals = [\n",
    "    \"athlete_id\", \"team\", \"opposing_team\", \"position\", \"home_away\"\n",
    "]\n",
    "\n",
    "known_future_categoricals = [\n",
    "    \"team\", \"opposing_team\", \"home_away\", \"position\"\n",
    "]\n",
    "\n",
    "known_future_numerics = [\n",
    "    \"season\"\n",
    "]\n",
    "\n",
    "# All numeric observed stats become observed past inputs\n",
    "def load_stat_df(stat_name: str) -> pd.DataFrame:\n",
    "    train_path = os.path.join(data_dir, f\"{stat_name}_2019_2023.csv\")\n",
    "    test_path  = os.path.join(data_dir, f\"{stat_name}_24tocurrent.csv\")\n",
    "\n",
    "    df_train = pd.read_csv(train_path, parse_dates=[\"date\"])\n",
    "    df_test  = pd.read_csv(test_path,  parse_dates=[\"date\"])\n",
    "\n",
    "    #df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    df_train = df_train.sort_values([\"athlete_id\", \"date\"]).reset_index(drop=True)\n",
    "    df_test = df_test.sort_values([\"athlete_id\", \"date\"]).reset_index(drop=True)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "class TFTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Each item returns everything needed for TFT:\n",
    "    - past observed: (T, E_obs)\n",
    "    - known future: (1, E_known)\n",
    "    - static categorical: (S_static,)\n",
    "    - target y\n",
    "    \"\"\"\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.samples[idx]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(s[\"past_observed\"], dtype=torch.float32),\n",
    "            torch.tensor(s[\"future_known\"], dtype=torch.float32),\n",
    "            torch.tensor(s[\"static_cat\"], dtype=torch.long),\n",
    "            torch.tensor(s[\"y\"], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CORRECTED: make_tft_sequences - Separate Train/Test\n",
    "# ============================================================\n",
    "\n",
    "def make_tft_sequences(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    window: int,\n",
    "    threshold: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build training/test sequences using TFT input format.\n",
    "    Properly separates train and test data.\n",
    "    Label encoders are fit on train, then applied to test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define observed numeric features (stats)\n",
    "    numeric_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    observed_past = [\n",
    "        c for c in numeric_cols\n",
    "        if c not in [\"season\"] and c != target_col and c != \"label\"\n",
    "    ]\n",
    "\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Helper to safely encode with an <UNK> token\n",
    "    def fit_encoder_with_unk(series):\n",
    "        # Add <UNK> to the unique values found in training\n",
    "        unique_vals = series.astype(str).unique().tolist()\n",
    "        unique_vals.append(\"<UNK>\")\n",
    "        le = LabelEncoder()\n",
    "        le.fit(unique_vals)\n",
    "        return le\n",
    "\n",
    "    def transform_with_unk(le, series):\n",
    "        # Map knowns to their index, unknowns to the index of <UNK>\n",
    "        unk_idx = le.transform([\"<UNK>\"])[0]\n",
    "        classes_set = set(le.classes_)\n",
    "        \n",
    "        return series.astype(str).apply(\n",
    "            lambda x: le.transform([x])[0] if x in classes_set else unk_idx\n",
    "        )\n",
    "\n",
    "    # Fit encoders on TRAIN\n",
    "    all_cats = list(set(static_categoricals + known_future_categoricals))\n",
    "    for cat in all_cats:\n",
    "        label_encoders[cat] = fit_encoder_with_unk(df_train[cat])\n",
    "\n",
    "    # Transform both train and test\n",
    "    df_train_encoded = df_train.copy()\n",
    "    df_test_encoded = df_test.copy()\n",
    "\n",
    "    for cat, le in label_encoders.items():\n",
    "        df_train_encoded[cat] = transform_with_unk(le, df_train[cat])\n",
    "        df_test_encoded[cat] = transform_with_unk(le, df_test[cat])\n",
    "\n",
    "    # Calculate and store Normalization Stats from TRAIN data\n",
    "    scaler_stats = {}\n",
    "    for col in observed_past:\n",
    "        mean = df_train[col].mean()\n",
    "        std = df_train[col].std()\n",
    "        scaler_stats[col] = (mean, std)\n",
    "    \n",
    "    samples_train = []\n",
    "    samples_test = []\n",
    "\n",
    "    # Process TRAIN data\n",
    "    for aid, g in df_train_encoded.groupby(\"athlete_id\"):\n",
    "        g = g.sort_values(\"date\")\n",
    "\n",
    "        if len(g) <= window:\n",
    "            continue\n",
    "\n",
    "        # static categorical encodings\n",
    "        static_vals = [\n",
    "            g[\"athlete_id\"].iloc[0],\n",
    "            g[\"team\"].iloc[0],\n",
    "            g[\"opposing_team\"].iloc[0],\n",
    "            g[\"position\"].iloc[0],\n",
    "            g[\"home_away\"].iloc[0],\n",
    "        ]\n",
    "\n",
    "        for t in range(window, len(g)):\n",
    "            # observed past stats\n",
    "            past_obs = g[observed_past].iloc[t-window : t].values.astype(\"float32\")\n",
    "\n",
    "            #Apply Normalization to past_obs (TRAIN)\n",
    "            for i, col in enumerate(observed_past):\n",
    "                mean, std = scaler_stats[col]\n",
    "                # Apply Z-score normalization using training set stats\n",
    "                if std > 1e-6:\n",
    "                    past_obs[:, i] = (past_obs[:, i] - mean) / std\n",
    "                else:\n",
    "                    past_obs[:, i] = 0.0 # Handle constant features\n",
    "            \n",
    "            # known future at decoder step (t)\n",
    "            fut_known_numeric = g[known_future_numerics].iloc[t:t+1].values.astype(\"float32\")\n",
    "            fut_known_cat_vals = [\n",
    "                g[\"team\"].iloc[t],\n",
    "                g[\"opposing_team\"].iloc[t],\n",
    "                g[\"home_away\"].iloc[t],\n",
    "                g[\"position\"].iloc[t],\n",
    "            ]\n",
    "            fut_known_cat = np.array(fut_known_cat_vals, dtype=\"float32\").reshape(1, -1) #reshaping to 1,n\n",
    "            future_known = np.concatenate([fut_known_numeric, fut_known_cat], axis=-1)\n",
    "\n",
    "            y = g[\"label\"].iloc[t]\n",
    "\n",
    "            sample = {\n",
    "                \"past_observed\": past_obs,\n",
    "                \"future_known\": future_known,\n",
    "                \"static_cat\": np.array(static_vals, dtype=\"int64\"),\n",
    "                \"y\": y,\n",
    "            }\n",
    "            samples_train.append(sample)\n",
    "\n",
    "    # Process TEST data\n",
    "    for aid, g in df_test_encoded.groupby(\"athlete_id\"):\n",
    "        g = g.sort_values(\"date\")\n",
    "\n",
    "        if len(g) <= window:\n",
    "            continue\n",
    "\n",
    "        static_vals = [\n",
    "            g[\"athlete_id\"].iloc[0],\n",
    "            g[\"team\"].iloc[0],\n",
    "            g[\"opposing_team\"].iloc[0],\n",
    "            g[\"position\"].iloc[0],\n",
    "            g[\"home_away\"].iloc[0],\n",
    "        ]\n",
    "\n",
    "        for t in range(window, len(g)):\n",
    "            past_obs = g[observed_past].iloc[t-window : t].values.astype(\"float32\")\n",
    "\n",
    "            # Apply Normalization to past_obs (TEST) using TRAIN stats\n",
    "            for i, col in enumerate(observed_past):\n",
    "                mean, std = scaler_stats[col]\n",
    "                if std > 1e-6:\n",
    "                    past_obs[:, i] = (past_obs[:, i] - mean) / std\n",
    "                else:\n",
    "                    past_obs[:, i] = 0.0\n",
    "\n",
    "\n",
    "            fut_known_numeric = g[known_future_numerics].iloc[t:t+1].values.astype(\"float32\")\n",
    "            fut_known_cat_vals = [\n",
    "                g[\"team\"].iloc[t],\n",
    "                g[\"opposing_team\"].iloc[t],\n",
    "                g[\"home_away\"].iloc[t],\n",
    "                g[\"position\"].iloc[t],\n",
    "            ]\n",
    "            fut_known_cat = np.array(fut_known_cat_vals, dtype=\"float32\").reshape(1, -1) #reshaping to 1,n\n",
    "            future_known = np.concatenate([fut_known_numeric, fut_known_cat], axis=-1)\n",
    "\n",
    "            y = g[\"label\"].iloc[t]\n",
    "\n",
    "            sample = {\n",
    "                \"past_observed\": past_obs,\n",
    "                \"future_known\": future_known,\n",
    "                \"static_cat\": np.array(static_vals, dtype=\"int64\"),\n",
    "                \"y\": y,\n",
    "            }\n",
    "            samples_test.append(sample)\n",
    "\n",
    "    return TFTDataset(samples_train), TFTDataset(samples_test), observed_past, label_encoders, scaler_stats\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. TFT BUILDING BLOCKS (GRN, VSN, LSTM, ATTENTION)\n",
    "# ============================================================\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, inp, hidden, out=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        out = out or inp\n",
    "\n",
    "        self.fc1 = nn.Linear(inp, hidden)\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc2 = nn.Linear(hidden, out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # gating\n",
    "        self.fc_gate = nn.Linear(out, out)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # skip\n",
    "        if inp != out:\n",
    "            self.skip = nn.Linear(inp, out)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x if self.skip is None else self.skip(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        gate = self.sigmoid(self.fc_gate(x))\n",
    "        return residual + gate * x\n",
    "\n",
    "\n",
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(self, n_inputs, d_inp, hidden_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "\n",
    "        # GRN to compute selection weights\n",
    "        self.weight_grn = GatedResidualNetwork(\n",
    "            n_inputs * d_inp, hidden_size, out=n_inputs, dropout=dropout\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # individual GRNs for each variable\n",
    "        self.var_grns = nn.ModuleList([\n",
    "            GatedResidualNetwork(d_inp, hidden_size, out=hidden_size, dropout=dropout)\n",
    "            for _ in range(n_inputs)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, n_vars, d_input)\n",
    "        \"\"\"\n",
    "        B, T, n_vars, d = x.shape\n",
    "\n",
    "        # selection weights\n",
    "        flat = x.reshape(B, T, n_vars * d)\n",
    "        w = self.weight_grn(flat)  # (B, T, n_vars)\n",
    "        w = self.softmax(w).unsqueeze(-1)  # (B, T, n_vars, 1)\n",
    "\n",
    "        # transformed features\n",
    "        var_outs = []\n",
    "        for i, grn in enumerate(self.var_grns):\n",
    "            v = x[:, :, i, :]\n",
    "            var_outs.append(grn(v))\n",
    "        var_outs = torch.stack(var_outs, dim=2)  # (B, T, n_vars, hidden)\n",
    "\n",
    "        z = torch.sum(w * var_outs, dim=2)  # (B, T, hidden)\n",
    "        return z\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. TEMPORAL FUSION TRANSFORMER MODEL\n",
    "# ============================================================\n",
    "\n",
    "class TemporalFusionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size,\n",
    "        n_static_cat,\n",
    "        n_future,\n",
    "        n_past,\n",
    "        n_static_embeds: Dict[str, int],\n",
    "        past_dim: int,\n",
    "        num_heads=2,              \n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Embeddings for static categorical variables\n",
    "        self.static_emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(n_static_embeds[k], hidden_size)\n",
    "            for k in n_static_embeds\n",
    "        ])\n",
    "        self.num_static = len(n_static_embeds)\n",
    "\n",
    "        # 1) Static variable selection\n",
    "        self.static_vsn = VariableSelectionNetwork(\n",
    "            n_inputs=self.num_static,\n",
    "            d_inp=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # 2) Past observed VSN\n",
    "        self.past_vsn = VariableSelectionNetwork(\n",
    "            n_inputs=n_past,\n",
    "            d_inp=1,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # 3) Known future VSN\n",
    "        self.future_vsn = VariableSelectionNetwork(\n",
    "            n_inputs=n_future,\n",
    "            d_inp=1,\n",
    "            hidden_size=hidden_size,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # 4) LSTM Encoder & Decoder\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=hidden_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_size, hidden_size=hidden_size, batch_first=True\n",
    "        )\n",
    "\n",
    "        # 5) Attention layer\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            hidden_size, \n",
    "            num_heads=num_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 6) Final dense\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, past_obs, fut_known, static_cat):\n",
    "        \"\"\"\n",
    "        past_obs:   (B, T, n_past_total)\n",
    "        fut_known:  (B, 1, n_future_total)\n",
    "        static_cat: (B, n_static_cat)\n",
    "        \"\"\"\n",
    "\n",
    "        B, T, n_past_total = past_obs.shape\n",
    "\n",
    "        # Static \n",
    "        static_embs = []\n",
    "        for i, emb in enumerate(self.static_emb_layers):\n",
    "            static_embs.append(emb(static_cat[:, i]))\n",
    "        static_embs = torch.stack(static_embs, dim=1)  # (B, S_static, hidden)\n",
    "\n",
    "        # static VSN\n",
    "        static_repr = self.static_vsn(static_embs.unsqueeze(1))  # (B,1,hidden)\n",
    "        static_repr = static_repr.squeeze(1)  # (B, hidden)\n",
    "\n",
    "        # Past Observed \n",
    "        past_obs_exp = past_obs.unsqueeze(-1)  # (B,T,n_past,1)\n",
    "        z_past = self.past_vsn(past_obs_exp)   # (B,T,hidden)\n",
    "\n",
    "        # Known Future \n",
    "        fut_known_exp = fut_known.unsqueeze(-1)  # (B,1,n_future,1)\n",
    "        z_fut = self.future_vsn(fut_known_exp)   # (B,1,hidden)\n",
    "\n",
    "        # LSTM Encoder \n",
    "        enc_out, (h, c) = self.encoder(z_past)\n",
    "\n",
    "        # LSTM Decoder (horizon = 1)\n",
    "        dec_out, _ = self.decoder(z_fut, (h, c))\n",
    "\n",
    "        # Attention (context from encoder)\n",
    "        attn_out, _ = self.attn(dec_out, enc_out, enc_out)\n",
    "\n",
    "        # Final \n",
    "        logits = self.fc(attn_out).squeeze(1).squeeze(-1)  # (B,)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. MODEL CREATION FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def create_tft_model_from_dataset(\n",
    "    cfg: TFTConfig,\n",
    "    device,\n",
    "    df_train: pd.DataFrame,\n",
    "    df_test: pd.DataFrame,\n",
    "    parlay_tgt: str,\n",
    "    threshold: float,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates TFT model with proper train/test separation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # build label (binary) for both train and test\n",
    "    df_train = df_train.copy()\n",
    "    df_test = df_test.copy()\n",
    "    \n",
    "    df_train[\"label\"] = (df_train[parlay_tgt] >= threshold).astype(\"float32\")\n",
    "    df_test[\"label\"] = (df_test[parlay_tgt] >= threshold).astype(\"float32\")\n",
    "\n",
    "    # clean inf/nan\n",
    "    df_train = df_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    df_test = df_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    train_ds, test_ds, past_feat_list, label_encoders, scaler_stats = make_tft_sequences(\n",
    "        df_train=df_train,\n",
    "        df_test=df_test,\n",
    "        target_col=parlay_tgt,\n",
    "        window=cfg.n_past_games,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        #collate_fn=tft_collate_fn,\n",
    "    )\n",
    "    test_dl = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        #collate_fn=tft_collate_fn,\n",
    "    )\n",
    "\n",
    "    # determine category sizes from TRAIN data only\n",
    "    static_embed_sizes = {}\n",
    "    for cat in static_categoricals:\n",
    "        static_embed_sizes[cat] = len(label_encoders[cat].classes_)\n",
    "\n",
    "    n_static_cat = len(static_categoricals)\n",
    "    n_future = len(known_future_numerics) + len(known_future_categoricals)\n",
    "    n_past = len(past_feat_list)\n",
    "\n",
    "    model = TemporalFusionTransformer(\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        n_static_cat=n_static_cat,\n",
    "        n_future=n_future,\n",
    "        n_past=n_past,\n",
    "        n_static_embeds=static_embed_sizes,\n",
    "        past_dim=n_past,\n",
    "        num_heads=cfg.num_heads,\n",
    "        dropout=cfg.dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    return model, train_dl, test_dl, df_train, df_test, past_feat_list, label_encoders, scaler_stats\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. TRAINING LOOP (BINARY)\n",
    "# ============================================================\n",
    "\n",
    "def train_tft_binary(\n",
    "    model,\n",
    "    train_dl,\n",
    "    test_dl,\n",
    "    cfg: TFTConfig,\n",
    "):\n",
    "    # Calculate pos_weight (assuming you moved the calculation outside the function)\n",
    "    train_labels = [sample[\"y\"] for sample in train_dl.dataset.samples]\n",
    "    num_pos = sum(train_labels)\n",
    "    num_neg = len(train_labels) - num_pos\n",
    "    pos_weight_value = num_neg / num_pos\n",
    "    pos_weight_tensor = torch.tensor([pos_weight_value], device=device)\n",
    "\n",
    "    # 1. Setup\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=cfg.lr, \n",
    "        #weight_decay=cfg.weight_decay\n",
    "    )\n",
    "\n",
    "    # CHECKPOINTING VARIABLES\n",
    "    best_test_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    # 2. Training Loop\n",
    "    for epoch in range(1, cfg.n_epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        \n",
    "        # Training Phase\n",
    "        for past_obs, fut_known, static_cat, y in train_dl:\n",
    "            past_obs, fut_known, static_cat, y = past_obs.to(device), fut_known.to(device), static_cat.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            logits = model(past_obs, fut_known, static_cat)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient Clipping for Stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * y.size(0)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            train_correct += (preds == y).sum().item()\n",
    "\n",
    "        train_loss /= len(train_dl.dataset)\n",
    "        train_accuracy = 100. * train_correct / len(train_dl.dataset)\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for past_obs, fut_known, static_cat, y in test_dl:\n",
    "                past_obs, fut_known, static_cat, y = past_obs.to(device), fut_known.to(device), static_cat.to(device), y.to(device)\n",
    "\n",
    "                logits = model(past_obs, fut_known, static_cat)\n",
    "                loss = criterion(logits, y)\n",
    "                \n",
    "                test_loss += loss.item() * y.size(0)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                test_correct += (preds == y).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dl.dataset)\n",
    "        test_accuracy = 100. * test_correct / len(test_dl.dataset)\n",
    "        \n",
    "        # CHECKPOINTING LOGIC \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            # Save the state dictionary of the model (best weights found so far)\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        # Print Epoch Summary\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d}/{cfg.n_epochs} | \"\n",
    "            f\"Train L={train_loss:.4f} A={train_accuracy:.1f}% | \"\n",
    "            f\"Test L={test_loss:.4f} A={test_accuracy:.1f}%\"\n",
    "        )\n",
    "    # 3. Load Best Model and Return\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\nModel loaded best weights corresponding to Test Loss: {best_test_loss:.4f}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb33681-db55-4fce-b31a-816d80222fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. TFT PREDICTION UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def build_player_sequence_tft(\n",
    "    df_player: pd.DataFrame,\n",
    "    past_feat_list: List[str],\n",
    "    label_encoders: Dict,                  \n",
    "    scaler_stats: Dict,\n",
    "    static_categoricals: List[str],\n",
    "    known_future_categoricals: List[str],\n",
    "    known_future_numerics: List[str],\n",
    "    n_past_games: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a single inference sequence for TFT from a single player's history.\n",
    "    Applies label encoding to raw strings.\n",
    "    \"\"\"\n",
    "    df_player = df_player.sort_values(\"date\")\n",
    "\n",
    "    # Helper to safely encode value (handling Unknowns)\n",
    "    def safe_encode(cat_name, val):\n",
    "        le = label_encoders[cat_name]\n",
    "        val_str = str(val)\n",
    "        if val_str in le.classes_:\n",
    "            return le.transform([val_str])[0]\n",
    "        # Handle unknown/unseen categories (use <UNK> if exists, else 0)\n",
    "        if \"<UNK>\" in le.classes_:\n",
    "            return le.transform([\"<UNK>\"])[0]\n",
    "        return 0\n",
    "\n",
    "    # Extract static categorical values\n",
    "    static_vals = []\n",
    "    for cat in static_categoricals:\n",
    "        raw_val = df_player[cat].iloc[-1]\n",
    "        encoded_val = safe_encode(cat, raw_val) # Encode here\n",
    "        static_vals.append(encoded_val)\n",
    "        \n",
    "    static_vals = np.array(static_vals, dtype=\"int64\")\n",
    "\n",
    "    # Past observed features\n",
    "    past_rows = df_player.iloc[-n_past_games-1:-1]\n",
    "    past_obs = past_rows[past_feat_list].values.astype(\"float32\")\n",
    "\n",
    "    # Apply Normalization using TRAIN stats\n",
    "    for i, col in enumerate(past_feat_list):\n",
    "            mean, std = scaler_stats[col]\n",
    "            if std > 1e-6:\n",
    "                past_obs[:, i] = (past_obs[:, i] - mean) / std\n",
    "            else:\n",
    "                past_obs[:, i] = 0.0\n",
    "\n",
    "    # Known future features\n",
    "    future_row = df_player.iloc[-1]\n",
    "\n",
    "    known_cat_vals = [\n",
    "        safe_encode(cat, future_row[cat]) \n",
    "        for cat in known_future_categoricals\n",
    "    ]\n",
    "    known_num_vals = [future_row[c] for c in known_future_numerics]\n",
    "\n",
    "    future_known = np.array(known_num_vals + known_cat_vals, dtype=\"float32\")\n",
    "    future_known = future_known.reshape(1, -1)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(past_obs, dtype=torch.float32).unsqueeze(0),      # (1,T,n_past)\n",
    "        torch.tensor(future_known, dtype=torch.float32).unsqueeze(0),  # (1,1,n_future)\n",
    "        torch.tensor(static_vals, dtype=torch.long).unsqueeze(0),      # (1,S_static)\n",
    "    )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_tft_probability(\n",
    "    model,\n",
    "    df_player: pd.DataFrame,\n",
    "    past_feat_list: List[str],\n",
    "    label_encoders: Dict,          \n",
    "    scaler_stats: Dict,\n",
    "    threshold: float,\n",
    "    stat_col: str,\n",
    "    n_past_games: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute probability P(stat >= threshold) using the TFT model.\n",
    "    \"\"\"\n",
    "    if len(df_player) <= n_past_games:\n",
    "        return None\n",
    "\n",
    "    # Pass label_encoders down to the builder\n",
    "    past_obs, fut_known, static_cat = build_player_sequence_tft(\n",
    "        df_player,\n",
    "        past_feat_list,\n",
    "        label_encoders,           # PASS DOWN\n",
    "        scaler_stats,\n",
    "        static_categoricals,\n",
    "        known_future_categoricals,\n",
    "        known_future_numerics,\n",
    "        n_past_games=n_past_games,\n",
    "    )\n",
    "\n",
    "    past_obs = past_obs.to(device)\n",
    "    fut_known = fut_known.to(device)\n",
    "    static_cat = static_cat.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    logits = model(past_obs, fut_known, static_cat)\n",
    "    prob = torch.sigmoid(logits).item()\n",
    "\n",
    "    return prob\n",
    "\n",
    "# Update parlay engine to handle label_encoders\n",
    "def parlay_probability_tft(models_info):\n",
    "    \n",
    "    probs = []\n",
    "    for info in models_info:\n",
    "        p = predict_tft_probability(\n",
    "            model=info[\"model\"],\n",
    "            df_player=info[\"df_player\"],\n",
    "            past_feat_list=info[\"past_feat_list\"],\n",
    "            label_encoders=info[\"label_encoders\"],  \n",
    "            scaler_stats=info[\"scaler_stats\"],       \n",
    "            threshold=info[\"threshold\"],\n",
    "            stat_col=info[\"stat_col\"],\n",
    "            n_past_games=info[\"n_past_games\"],\n",
    "        )\n",
    "        if p is None:\n",
    "            return None\n",
    "        probs.append(p)\n",
    "\n",
    "    # assume independence for parlay\n",
    "    parlay_p = np.prod(probs)\n",
    "    return parlay_p\n",
    "\n",
    "# ============================================================\n",
    "# 8. PARLAY ENGINE (MULTI-LEG)\n",
    "# ============================================================\n",
    "\n",
    "def parlay_probability_tft(models_info):\n",
    "    \"\"\"\n",
    "    models_info: list of dicts, each containing:\n",
    "      {\n",
    "        \"model\": trained_model,\n",
    "        \"df_player\": player's dataframe subset,\n",
    "        \"past_feat_list\": list of past features,\n",
    "        \"label_encoders\": dict of label encoders,  <-- NEW REQUIREMENT\n",
    "        \"threshold\": float,\n",
    "        \"stat_col\": str,\n",
    "        \"n_past_games\": int\n",
    "      }\n",
    "\n",
    "    Returns:\n",
    "        product of independent probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    probs = []\n",
    "    for info in models_info:\n",
    "        # We must pass 'label_encoders' here now\n",
    "        p = predict_tft_probability(\n",
    "            model=info[\"model\"],\n",
    "            df_player=info[\"df_player\"],\n",
    "            past_feat_list=info[\"past_feat_list\"],\n",
    "            label_encoders=info[\"label_encoders\"],  \n",
    "            scaler_stats=info[\"scaler_stats\"],    \n",
    "            threshold=info[\"threshold\"],\n",
    "            stat_col=info[\"stat_col\"],\n",
    "            n_past_games=info[\"n_past_games\"],\n",
    "        )\n",
    "        if p is None:\n",
    "            return None\n",
    "        probs.append(p)\n",
    "\n",
    "    # assume independence for parlay\n",
    "    parlay_p = np.prod(probs)\n",
    "    return parlay_p\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. CALIBRATION METRICS & KELLY ROI + EXAMPLES\n",
    "# ============================================================\n",
    "\n",
    "# -------------------------------\n",
    "# Expected Calibration Error\n",
    "# -------------------------------\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    bins = np.linspace(0, 1, n_bins+1)\n",
    "    probs = np.array(probs)\n",
    "    labels = np.array(labels)\n",
    "    ece = 0.0\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        mask = (probs >= lo) & (probs < hi)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        avg_conf = probs[mask].mean()\n",
    "        avg_acc  = labels[mask].mean()\n",
    "        ece += (mask.sum() / len(probs)) * abs(avg_conf - avg_acc)\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Positive Calibration Error\n",
    "# -------------------------------\n",
    "def compute_pce(probs, labels):\n",
    "    \"\"\"\n",
    "    For positive outcomes only (label=1).\n",
    "    \"\"\"\n",
    "    probs = np.array(probs)\n",
    "    labels = np.array(labels)\n",
    "    mask = labels == 1\n",
    "    if mask.sum() == 0:\n",
    "        return 0\n",
    "    return np.abs(probs[mask].mean() - 1.0)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Kelly Criterion ROI\n",
    "# -------------------------------\n",
    "def kelly_fraction(p, odds):\n",
    "    \"\"\"\n",
    "    p: model probability\n",
    "    odds: decimal odds\n",
    "    \"\"\"\n",
    "    b = odds - 1\n",
    "    return (p * (b + 1) - 1) / b\n",
    "\n",
    "\n",
    "def compute_kelly_roi(model_probs, labels, odds=1.91):\n",
    "    \"\"\"\n",
    "    Compute average ROI using Kelly betting on every prediction.\n",
    "    \"\"\"\n",
    "    rois = []\n",
    "    for p, y in zip(model_probs, labels):\n",
    "        f = kelly_fraction(p, odds)\n",
    "        f = max(f, 0)  # no negative Kelly\n",
    "        if y == 1:\n",
    "            rois.append(f * (odds - 1))\n",
    "        else:\n",
    "            rois.append(-f)\n",
    "    return np.mean(rois)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Example Usage (Single + Parlay)\n",
    "# -------------------------------\n",
    "def example_usage_tft(\n",
    "    df,\n",
    "    models,\n",
    "    past_feat_lists,\n",
    "    thresholds,\n",
    "    stat_cols,\n",
    "    player_ids,\n",
    "    cfg: TFTConfig,\n",
    "):\n",
    "    \"\"\"\n",
    "    Simple demonstration using trained TFT models.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== TFT Example Usage ===\")\n",
    "\n",
    "    # -------------------\n",
    "    # Single leg example\n",
    "    # -------------------\n",
    "    pid = player_ids[0]\n",
    "    df_player = df[df[\"athlete_id\"] == pid]\n",
    "\n",
    "    p_single = predict_tft_probability(\n",
    "        model=models[0],\n",
    "        df_player=df_player,\n",
    "        past_feat_list=past_feat_lists[0],\n",
    "        threshold=thresholds[0],\n",
    "        stat_col=stat_cols[0],\n",
    "        n_past_games=cfg.n_past_games,\n",
    "    )\n",
    "    print(f\"Single-leg model probability: {p_single:.4f}\")\n",
    "\n",
    "    # -------------------\n",
    "    # Multi-leg parlay\n",
    "    # -------------------\n",
    "    models_info = []\n",
    "    for m, pid, plist, thresh, s_col in zip(\n",
    "        models, player_ids, past_feat_lists, thresholds, stat_cols\n",
    "    ):\n",
    "        dfp = df[df[\"athlete_id\"] == pid]\n",
    "        models_info.append({\n",
    "            \"model\": m,\n",
    "            \"df_player\": dfp,\n",
    "            \"past_feat_list\": plist,\n",
    "            \"threshold\": thresh,\n",
    "            \"stat_col\": s_col,\n",
    "            \"n_past_games\": cfg.n_past_games,\n",
    "        })\n",
    "\n",
    "    p_parlay = parlay_probability_tft(models_info)\n",
    "    print(f\"Parlay Probability = {p_parlay:.5f}\")\n",
    "\n",
    "    return p_single, p_parlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f8e15f-fd16-43b4-b746-e76e1f4c06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. MODEL SAVING & LOADING UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def save_tft_model(model, config: TFTConfig, feature_info, path: str):\n",
    "    \"\"\"\n",
    "    Saves TFT model + config + feature lists.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    checkpoint = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"config\": config,\n",
    "        \"feature_info\": feature_info,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"[TFT] Model saved to: {path}\")\n",
    "\n",
    "\n",
    "def load_tft_model(path: str):\n",
    "    \"\"\"\n",
    "    Loads a TFT model from disk and rebuilds it with stored config.\n",
    "    Returns:\n",
    "        model, config, feature_info\n",
    "    \"\"\"\n",
    "\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    cfg: TFTConfig = checkpoint[\"config\"]\n",
    "    feature_info = checkpoint[\"feature_info\"]\n",
    "\n",
    "    model = TemporalFusionTransformer(\n",
    "        past_observed_size=feature_info[\"past_obs_size\"],\n",
    "        known_future_size=feature_info[\"known_future_size\"],\n",
    "        static_categorical_sizes=feature_info[\"static_cat_sizes\"],\n",
    "        known_categorical_sizes=feature_info[\"future_cat_sizes\"],\n",
    "        hidden_size=cfg.hidden_size,\n",
    "        dropout=cfg.dropout,\n",
    "        num_heads=cfg.num_heads,\n",
    "        weight_norm=cfg.weight_norm,\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    print(f\"[TFT] Model loaded from: {path}\")\n",
    "\n",
    "    return model, cfg, feature_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5dcbeb0-9c05-43b7-94c1-f6c0022b1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 11. FULL TESTING SUITE FOR TFT MODELS & DATA LOADERS\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# TFT Dataset: Player-centric sequences with past + static features\n",
    "# ---------------------------------------------------\n",
    "class PlayerStatsTFTDataset(Dataset):\n",
    "    def __init__(self, df, past_features, numeric_static_features, categorical_static_features, target_col, n_past_games=5):\n",
    "        \"\"\"\n",
    "        df: full DataFrame (2019-2023 or 2024)\n",
    "        past_features: dynamic features to feed the LSTM part\n",
    "        numeric_static_features: numeric static features (season, etc.)\n",
    "        categorical_static_features: categorical static features (team, home_away)\n",
    "        target_col: which column to predict (e.g., 'REC')\n",
    "        n_past_games: how many past games to include per sample\n",
    "        \"\"\"\n",
    "        self.sequences = []\n",
    "        self.targets = []\n",
    "        self.static_numeric = []\n",
    "        self.static_categorical = []\n",
    "\n",
    "        # Label encode categorical static features\n",
    "        self.label_encoders = {}\n",
    "        for col in categorical_static_features:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            self.label_encoders[col] = le\n",
    "\n",
    "        # Group by player\n",
    "        grouped = df.groupby(\"athlete_id\")\n",
    "        for _, g in grouped:\n",
    "            g = g.sort_values(\"date\")\n",
    "            for i in range(n_past_games, len(g)):\n",
    "                past_data = g[past_features].iloc[i - n_past_games:i].values.astype(float)\n",
    "                static_numeric = g[numeric_static_features].iloc[i].values.astype(float)\n",
    "                static_categorical = g[categorical_static_features].iloc[i].values.astype(float)  # after LabelEncoding\n",
    "                target = g[target_col].iloc[i]\n",
    "\n",
    "                self.sequences.append(past_data)\n",
    "                self.static_numeric.append(static_numeric)\n",
    "                self.static_categorical.append(static_categorical)\n",
    "                self.targets.append(target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"past\": torch.tensor(self.sequences[idx], dtype=torch.float),\n",
    "            \"static_numeric\": torch.tensor(self.static_numeric[idx], dtype=torch.float),\n",
    "            \"static_categorical\": torch.tensor(self.static_categorical[idx], dtype=torch.long),\n",
    "            \"target\": torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Function to create TFT dataloaders\n",
    "# ---------------------------------------\n",
    "def make_tft_dataloaders(df_train, df_test, static_features, target_col, batch_size=64, n_past_games=5):\n",
    "    \"\"\"\n",
    "    Returns train and test dataloaders ready for TFT\n",
    "    \"\"\"\n",
    "    # Separate numeric vs categorical static features\n",
    "    numeric_static_features = [f for f in static_features if df_train[f].dtype in [np.int64, np.float64]]\n",
    "    categorical_static_features = [f for f in static_features if f not in numeric_static_features]\n",
    "\n",
    "    # All other features are past/dynamic features\n",
    "    all_features = df_train.columns.tolist()\n",
    "    past_features = [f for f in all_features if f not in static_features + [\"game_id\", \"date\", \"athlete_id\", \"display_name\", \"position\", target_col]]\n",
    "\n",
    "    train_ds = PlayerStatsTFTDataset(df_train, past_features, numeric_static_features, categorical_static_features, target_col, n_past_games)\n",
    "    test_ds = PlayerStatsTFTDataset(df_test, past_features, numeric_static_features, categorical_static_features, target_col, n_past_games)\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_dl, test_dl, past_features, numeric_static_features, categorical_static_features\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Collect prediction probabilities & labels from test loader\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def collect_tft_predictions(model, test_loader):\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for batch in test_loader:\n",
    "        past_obs, fut_known, static_cat, labels = batch\n",
    "\n",
    "        past_obs = past_obs.to(device)\n",
    "        fut_known = fut_known.to(device)\n",
    "        static_cat = static_cat.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(past_obs, fut_known, static_cat)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    hat_p = np.concatenate(all_probs, axis=0).reshape(-1)\n",
    "    y_true = np.concatenate(all_labels, axis=0).reshape(-1)\n",
    "\n",
    "    return hat_p, y_true\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Full evaluation: ECE, PCE, Kelly ROI, Summary Output\n",
    "# ------------------------------------------------------------\n",
    "def run_tft_evaluation(\n",
    "    model,\n",
    "    test_loader,\n",
    "    n_bins: int = 10,\n",
    "    parlay_size: int = 2,\n",
    "    M: int = 1000,\n",
    "    rng: np.random.Generator = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete evaluation pipeline for a trained TFT model.\n",
    "    Returns dict of metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 1. collect predictions\n",
    "    # -----------------------------------------\n",
    "    hat_p, y_true = collect_tft_predictions(model, test_loader)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2. ECE\n",
    "    # -----------------------------------------\n",
    "    ece = compute_ece(hat_p, y_true, n_bins=n_bins)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3. Positive Calibration Error\n",
    "    # -----------------------------------------\n",
    "    pce = compute_pce(hat_p, y_true)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 4. Kelly ROI (per-leg)\n",
    "    # -----------------------------------------\n",
    "    kelly = compute_kelly_roi(hat_p, y_true)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 5. L-Leg Parlay Sampling\n",
    "    # -----------------------------------------\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    parlay_probs = []\n",
    "    parlay_outcomes = []\n",
    "\n",
    "    for _ in range(M):\n",
    "        idx = rng.choice(len(hat_p), size=parlay_size, replace=False)\n",
    "\n",
    "        p_leg = hat_p[idx]\n",
    "        y_leg = y_true[idx]\n",
    "\n",
    "        p_parlay = float(np.prod(p_leg))\n",
    "        y_parlay = float(np.all(y_leg == 1))\n",
    "\n",
    "        parlay_probs.append(p_parlay)\n",
    "        parlay_outcomes.append(y_parlay)\n",
    "\n",
    "    parlay_probs = np.array(parlay_probs)\n",
    "    parlay_outcomes = np.array(parlay_outcomes)\n",
    "\n",
    "    parlay_pce = np.mean(np.abs(parlay_probs - parlay_outcomes))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 6. Kelly ROI for parlays\n",
    "    # -----------------------------------------\n",
    "    parlay_kelly = compute_kelly_roi(parlay_probs, parlay_outcomes)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"hat_p\": hat_p,\n",
    "        \"y_true\": y_true,\n",
    "        \"ece\": ece,\n",
    "        \"pce\": pce,\n",
    "        \"kelly_roi\": kelly,\n",
    "        \"parlay_pce\": parlay_pce,\n",
    "        \"parlay_kelly_roi\": parlay_kelly,\n",
    "        \"parlay_probs\": parlay_probs,\n",
    "        \"parlay_outcomes\": parlay_outcomes,\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# END-TO-END DEMO: Train → Evaluate → Predict → Parlay\n",
    "# ------------------------------------------------------------\n",
    "def tft_end_to_end_demo(df, model, train_loader, test_loader, feat_info, cfg, player_name, stat_name, threshold):\n",
    "    \n",
    "    # Retrieve necessary metadata\n",
    "    past_feat_list = feat_info[\"past_features\"]\n",
    "    label_encoders = feat_info[\"label_encoders\"]\n",
    "    scaler_stats = feat_info[\"scaler_stats\"]\n",
    "\n",
    "    # 1. Run full model evaluation\n",
    "    print(\"===== TFT Evaluation Suite =====\")\n",
    "    # The evaluation function should also be updated to accept and use scaler_stats if needed\n",
    "    results = run_tft_evaluation(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        parlay_size=2,\n",
    "        M=1000,\n",
    "        n_bins=10,\n",
    "    )\n",
    "    \n",
    "    # 2. Single Player Prediction\n",
    "    df_player = df[df[\"display_name\"] == player_name]\n",
    "    \n",
    "    p_single = predict_tft_probability(\n",
    "        model=model,\n",
    "        df_player=df_player,\n",
    "        past_feat_list=past_feat_list,\n",
    "        label_encoders=label_encoders,\n",
    "        scaler_stats=scaler_stats,\n",
    "        threshold=threshold,\n",
    "        stat_col=stat_name,\n",
    "        n_past_games=cfg.n_past_games,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nSingle-leg probability for {player_name}: {p_single:.4f}\")\n",
    "\n",
    "    # 3. Multi-Leg Parlay (self-parlay example)\n",
    "    parlay_input_2_leg = [\n",
    "        # Leg 1\n",
    "        {\n",
    "            \"model\": model, \"df_player\": df_player, \"past_feat_list\": past_feat_list,\n",
    "            \"label_encoders\": label_encoders, \"scaler_stats\": scaler_stats, \n",
    "            \"threshold\": threshold, \"stat_col\": stat_name, \"n_past_games\": cfg.n_past_games,\n",
    "        },\n",
    "        # Leg 2\n",
    "        {\n",
    "            \"model\": model, \"df_player\": df_player, \"past_feat_list\": past_feat_list,\n",
    "            \"label_encoders\": label_encoders, \"scaler_stats\": scaler_stats, \n",
    "            \"threshold\": threshold, \"stat_col\": stat_name, \"n_past_games\": cfg.n_past_games,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    p_parlay = parlay_probability_tft(parlay_input_2_leg)\n",
    "    print(f\"Self-parlay (2 legs): {p_parlay:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"model_eval\": results,\n",
    "        \"single_prob\": p_single,\n",
    "        \"parlay_prob\": p_parlay,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500b0ccc-9c78-4bf6-a85b-87c81c45c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Positive Weight: 1.14\n",
      "Epoch 01/15 | Train L=0.6272 A=69.9% | Test L=0.6911 A=67.8%\n",
      "Epoch 02/15 | Train L=0.6182 A=70.2% | Test L=0.6500 A=65.8%\n",
      "Epoch 03/15 | Train L=0.6160 A=70.5% | Test L=0.6640 A=67.5%\n",
      "Epoch 04/15 | Train L=0.6154 A=70.5% | Test L=0.6542 A=67.5%\n",
      "Epoch 05/15 | Train L=0.6149 A=70.6% | Test L=0.6506 A=66.0%\n",
      "Epoch 06/15 | Train L=0.6143 A=70.4% | Test L=0.6513 A=65.4%\n",
      "Epoch 07/15 | Train L=0.6141 A=70.6% | Test L=0.6738 A=66.2%\n",
      "Epoch 08/15 | Train L=0.6145 A=70.4% | Test L=0.6498 A=65.2%\n",
      "Epoch 09/15 | Train L=0.6131 A=70.6% | Test L=0.6471 A=65.9%\n",
      "Epoch 10/15 | Train L=0.6103 A=70.8% | Test L=0.6833 A=62.2%\n",
      "Epoch 11/15 | Train L=0.6093 A=71.0% | Test L=0.6606 A=63.0%\n",
      "Epoch 12/15 | Train L=0.6083 A=71.1% | Test L=0.7118 A=58.7%\n",
      "Epoch 13/15 | Train L=0.6061 A=71.2% | Test L=0.6849 A=61.7%\n",
      "Epoch 14/15 | Train L=0.6045 A=71.3% | Test L=0.6788 A=62.1%\n",
      "Epoch 15/15 | Train L=0.5996 A=71.8% | Test L=0.6920 A=64.5%\n",
      "\n",
      "Model loaded best weights corresponding to Test Loss: 0.6471\n",
      "===== TFT Evaluation Suite =====\n",
      "\n",
      "Single-leg probability for Xavier Worthy: 0.7152\n",
      "Self-parlay (2 legs): 0.5115\n",
      "\n",
      "=== Model Training Complete ===\n",
      "Train samples: 18195\n",
      "Test samples: 4900\n",
      "\n",
      "=======================================================\n",
      "        TFT General Model Quality Metrics (Section 12 Output)        \n",
      "=======================================================\n",
      "Single-leg ECE: 0.1133\n",
      "Positive Calibration Error (PCE): 0.3789\n",
      "Single-leg Kelly ROI: 0.0676\n",
      "L-leg PCE (L=2): 0.3119\n",
      "Parlay Kelly ROI: 0.0032\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 12: Running the Custom TFT Model Pipeline\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "cfg = TFTConfig(\n",
    "    n_past_games=5,\n",
    "    batch_size=64,\n",
    "    hidden_size=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.1,\n",
    "    n_epochs=15,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "# Setting inputs\n",
    "player_name = 'Xavier Worthy'\n",
    "stat_name = 'receiving'\n",
    "parlay_tgt = 'REC'\n",
    "threshold = 3.0  # Example: predict if REC >= 5\n",
    "\n",
    "df_train, df_test = load_stat_df(stat_name)\n",
    "\n",
    "# Create model and dataloaders - pass BOTH dataframes\n",
    "model, train_dl, test_dl, df_train_processed, df_test_processed, past_feat_list, label_encoders, scaler_stats = create_tft_model_from_dataset(\n",
    "    cfg=cfg,\n",
    "    device=device,\n",
    "    df_train=df_train,\n",
    "    df_test=df_test,\n",
    "    parlay_tgt=parlay_tgt,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "# Count positive (1) and negative (0) labels in the training set\n",
    "train_labels = [sample[\"y\"] for sample in train_dl.dataset.samples]\n",
    "num_pos = sum(train_labels)\n",
    "num_neg = len(train_labels) - num_pos\n",
    "\n",
    "# Calculate the positive weight\n",
    "pos_weight_value = num_neg / num_pos\n",
    "pos_weight_tensor = torch.tensor([pos_weight_value], device=device)\n",
    "print(f\"Calculated Positive Weight: {pos_weight_value:.2f}\")\n",
    "\n",
    "# Train the model (trains on train_dl, validates on test_dl)\n",
    "trained_model = train_tft_binary(model, train_dl, test_dl, cfg)\n",
    "\n",
    "# Save the model with metadata\n",
    "feat_info = {\n",
    "    \"past_features\": past_feat_list,\n",
    "    \"label_encoders\": label_encoders,\n",
    "    \"scaler_stats\": scaler_stats \n",
    "}\n",
    "\n",
    "\n",
    "# For prediction, you can now use either train or test data\n",
    "# Example with test data\n",
    "results = tft_end_to_end_demo(\n",
    "    df=df_test_processed,  # Use test data for evaluation\n",
    "    model=trained_model,\n",
    "    train_loader=train_dl,\n",
    "    test_loader=test_dl,\n",
    "    feat_info=feat_info,\n",
    "    cfg=cfg,\n",
    "    player_name=player_name,\n",
    "    stat_name=parlay_tgt,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "print(\"\\n=== Model Training Complete ===\")\n",
    "print(f\"Train samples: {len(train_dl.dataset)}\")\n",
    "print(f\"Test samples: {len(test_dl.dataset)}\")\n",
    "\n",
    "# Assuming 'results' is the output dictionary from tft_end_to_end_demo\n",
    "metrics = results[\"model_eval\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"        TFT General Model Quality Metrics (Section 12 Output)        \")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Restore the essential metric output from the 'model_eval' dictionary\n",
    "print(f\"Single-leg ECE: {metrics['ece']:.4f}\")\n",
    "print(f\"Positive Calibration Error (PCE): {metrics['pce']:.4f}\")\n",
    "print(f\"Single-leg Kelly ROI: {metrics['kelly_roi']:.4f}\")\n",
    "print(f\"L-leg PCE (L=2): {metrics['parlay_pce']:.4f}\")\n",
    "print(f\"Parlay Kelly ROI: {metrics['parlay_kelly_roi']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7567bf65-9cfb-4c69-881a-d7758b445146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Calculating General Model Metrics... ===\n",
      "\n",
      "=======================================================\n",
      "        TFT General Model Quality Metrics (Evaluation on Test Set)        \n",
      "=======================================================\n",
      "Single-leg ECE (Expected Calibration Error): 0.1133\n",
      "Positive Calibration Error (Single-Leg PCE): 0.3789\n",
      "Single-leg Kelly ROI: 0.0676\n",
      "Multi-leg Calibration Metric (L=2 PCE): 0.3025\n",
      "Parlay Kelly ROI: 0.0054\n",
      "\n",
      "=======================================================\n",
      "             Custom Parlay Prediction Result (Instance-Specific)           \n",
      "=======================================================\n",
      "Leg 1 Probability (Travis Kelce REC >= 5.0): 0.93263\n",
      "Leg 2 Probability (Rashee Rice REC >= 5.0): 0.95436\n",
      "-------------------------------------------------------\n",
      "Combined Parlay Probability (Leg 1 * Leg 2): 0.89007\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 13. TWO-LEG PARLAY DEMO (Specific Inputs)\n",
    "# ============================================================\n",
    "\n",
    "##  INSTRUCTIONS:  ##\n",
    "# Standard sampling,bins, parlay size per milestone II\n",
    "# stat_A_name and stat_B_name must match the stat the model was trained for! \n",
    "# \n",
    "##\n",
    "\n",
    "# --- Configuration ---\n",
    "PARLAY_SIZE = 2\n",
    "M_SAMPLES = 1000\n",
    "N_BINS = 10\n",
    "\n",
    "# --- Define inputs for Leg 1 ---\n",
    "player_A_name = \"Travis Kelce\"\n",
    "stat_A_name = \"REC\"             # Must match the stat the model was trained for\n",
    "threshold_A = 5.0\n",
    "\n",
    "# --- Define inputs for Leg 2 ---\n",
    "player_B_name = \"Rashee Rice\"\n",
    "stat_B_name = \"REC\"\n",
    "threshold_B = 5.0\n",
    "\n",
    "\n",
    "# 1. Run Full Model Evaluation (General Metrics)\n",
    "print(\"\\n=== Calculating General Model Metrics... ===\")\n",
    "eval_metrics = run_tft_evaluation(\n",
    "    model=trained_model,\n",
    "    test_loader=test_dl,\n",
    "    parlay_size=PARLAY_SIZE,\n",
    "    M=M_SAMPLES,\n",
    "    n_bins=N_BINS,\n",
    ")\n",
    "\n",
    "# 2. Prepare Custom Parlay Data\n",
    "df_player_A = df_test_processed[df_test_processed[\"display_name\"] == player_A_name]\n",
    "df_player_B = df_test_processed[df_test_processed[\"display_name\"] == player_B_name]\n",
    "\n",
    "# 3. Calculate Individual Leg Probabilities\n",
    "p_leg_A, p_leg_B = None, None\n",
    "p_parlay_custom = None\n",
    "label_encoders = feat_info[\"label_encoders\"]\n",
    "past_feat_list = feat_info[\"past_features\"]\n",
    "scaler_stats = feat_info[\"scaler_stats\"]\n",
    "\n",
    "\n",
    "if not df_player_A.empty:\n",
    "    p_leg_A = predict_tft_probability(\n",
    "        model=trained_model, df_player=df_player_A, past_feat_list=past_feat_list,\n",
    "        label_encoders=label_encoders, scaler_stats=scaler_stats, threshold=threshold_A, stat_col=stat_A_name,\n",
    "        n_past_games=cfg.n_past_games,\n",
    "    )\n",
    "\n",
    "if not df_player_B.empty:\n",
    "    p_leg_B = predict_tft_probability(\n",
    "        model=trained_model, df_player=df_player_B, past_feat_list=past_feat_list,\n",
    "        label_encoders=label_encoders, scaler_stats=scaler_stats,\n",
    "        threshold=threshold_B, stat_col=stat_B_name, n_past_games=cfg.n_past_games,\n",
    "    )\n",
    "    \n",
    "# 4. Calculate Combined Parlay Probability\n",
    "if p_leg_A is not None and p_leg_B is not None:\n",
    "    p_parlay_custom = p_leg_A * p_leg_B\n",
    "\n",
    "\n",
    "# 5. Output All Results (Updated printing to show individual legs)\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"        TFT General Model Quality Metrics (Evaluation on Test Set)        \")\n",
    "print(\"=\"*55)\n",
    "\n",
    "print(f\"Single-leg ECE (Expected Calibration Error): {eval_metrics['ece']:.4f}\")\n",
    "print(f\"Positive Calibration Error (Single-Leg PCE): {eval_metrics['pce']:.4f}\")\n",
    "print(f\"Single-leg Kelly ROI: {eval_metrics['kelly_roi']:.4f}\")\n",
    "print(f\"Multi-leg Calibration Metric (L={PARLAY_SIZE} PCE): {eval_metrics['parlay_pce']:.4f}\")\n",
    "print(f\"Parlay Kelly ROI: {eval_metrics['parlay_kelly_roi']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"             Custom Parlay Prediction Result (Instance-Specific)           \")\n",
    "print(\"=\"*55)\n",
    "\n",
    "if p_leg_A is not None:\n",
    "    print(f\"Leg 1 Probability ({player_A_name} {stat_A_name} >= {threshold_A}): {p_leg_A:.5f}\")\n",
    "else:\n",
    "    print(f\"Leg 1 Probability ({player_A_name} {stat_A_name} >= {threshold_A}): Insufficient Data\")\n",
    "    \n",
    "if p_leg_B is not None:\n",
    "    print(f\"Leg 2 Probability ({player_B_name} {stat_B_name} >= {threshold_B}): {p_leg_B:.5f}\")\n",
    "else:\n",
    "    print(f\"Leg 2 Probability ({player_B_name} {stat_B_name} >= {threshold_B}): Insufficient Data\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "if p_parlay_custom is not None:\n",
    "    print(f\"Combined Parlay Probability (Leg 1 * Leg 2): {p_parlay_custom:.5f}\")\n",
    "else:\n",
    "    print(\"Combined Parlay Probability: Cannot be calculated (Data missing for one or both legs).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91360bc0-bf9b-44ba-a80a-8d237feb6f27",
   "metadata": {},
   "source": [
    "## Investigation\n",
    "\n",
    "    Increasing hidden layers size to 128 and number of heads to 4 from defaults.\n",
    "        Best test loss: Epoch 09/15 | Train L=0.6131 A=70.6% | Test L=0.6471 A=65.9%\n",
    "        Overall flow of learning is unstable still at increasing number of hidden & heads.\n",
    "        \n",
    "    Attempted adding L2 regularization to the ADAM optimizer at 1e-5.\n",
    "        Failed by increasing loss and providing further instability during training. Moving to 1e-3.\n",
    "        Best: Epoch 14/15 | Train L=0.7649 A=72.5% | Test L=0.8044 A=69.1%\n",
    "        Moving to weight_decay of 1e-2 which increased stability but still unstable learning.\n",
    "    Attempting a more base case to train on 'Xavier Worthy' getting over 3 receptions (should be highly likely).\n",
    "        This decreased overall accuracy range when running the model to around 65-66% without improvement\n",
    "\n",
    "Summary:\n",
    "\n",
    "    The model is very confident in its predictions even though the accuracy is relatively low (below 80%) and the loss ECE is high with .1133 (about .05-.1 expected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff4f38-6fec-41cd-a591-c1e9d3f2fb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
