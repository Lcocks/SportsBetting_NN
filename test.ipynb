{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "\n",
    "from lstm import train_dual_head_classifier, TrainConfig\n",
    "from tft import train_tft_classifier, TrainConfig\n",
    "from data_prep import add_over_under_label, prepare_receiving_sequences\n",
    "from metrics import compute_ece, compute_pace\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from player_utils import predict_player_over_prob\n",
    "\n",
    "from core_logic import compute_parlay_prob, load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/receiving_2019_2023.csv\")\n",
    "test_df  = pd.read_csv(\"data/receiving_24tocurrent.csv\")\n",
    "\n",
    "LINE_VALUE = 80      \n",
    "N_PAST_GAMES = 5\n",
    "HIDDEN_SIZE = 128\n",
    "STAT_COL  = \"YDS\"\n",
    "D_MODEL = 128\n",
    "\n",
    "\n",
    "train_df = add_over_under_label(train_df, stat_col=STAT_COL, line_value=LINE_VALUE, new_col=\"over_label\")\n",
    "test_df  = add_over_under_label(test_df,  stat_col=STAT_COL, line_value=LINE_VALUE, new_col=\"over_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train BCE loss: 0.2583\n",
      "Epoch 02 | Train BCE loss: 0.2435\n",
      "Epoch 03 | Train BCE loss: 0.2429\n",
      "Epoch 04 | Train BCE loss: 0.2418\n",
      "Epoch 05 | Train BCE loss: 0.2404\n",
      "Epoch 06 | Train BCE loss: 0.2404\n",
      "Epoch 07 | Train BCE loss: 0.2394\n",
      "Epoch 08 | Train BCE loss: 0.2391\n",
      "Epoch 09 | Train BCE loss: 0.2395\n",
      "Epoch 10 | Train BCE loss: 0.2379\n",
      "\n",
      "=== Train Metrics (Single-Leg + Parlay) ===\n",
      "AUC_train   : 0.8419\n",
      "ECE_train   : 0.0060\n",
      "PaCE2_train : 0.0161  (random 2-leg parlays)\n",
      "\n",
      "=== Test Metrics (Single-Leg + Parlay) ===\n",
      "AUC_test   : 0.8161\n",
      "ECE_test   : 0.0107\n",
      "PaCE2_test : 0.0163  (random 2-leg parlays)\n",
      "Saved model to models/lstm_dual_receiving_yds_line_80.0_past5_hid128.pt\n",
      "Saved metrics to metrics/lstm_dual_receiving_yds_line_80.0_past5_hid128_metrics.json\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, lengths_train, meta_train = prepare_receiving_sequences(\n",
    "    train_df,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "X_test, y_test, lengths_test, meta_test = prepare_receiving_sequences(\n",
    "    test_df,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "cfg = TrainConfig(\n",
    "    n_epochs=10,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    device=\"auto\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_result = train_dual_head_classifier(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    lengths=lengths_train,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "model = train_result[\"model\"]\n",
    "history = train_result[\"history\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "len_train_t = torch.tensor(lengths_train, dtype=torch.long).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_reg_train, logits_train = model(X_train_t, len_train_t)\n",
    "    probs_train = torch.sigmoid(logits_train).cpu().numpy()\n",
    "\n",
    "y_true_train = np.asarray(y_train)\n",
    "\n",
    "auc_train   = roc_auc_score(y_true_train, probs_train)\n",
    "ece_train   = compute_ece(y_true_train, probs_train)\n",
    "pace2_train = compute_pace(y_true_train, probs_train, L=2)\n",
    "\n",
    "print(\"\\n=== Train Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_train   : {auc_train:.4f}\")\n",
    "print(f\"ECE_train   : {ece_train:.4f}\")\n",
    "print(f\"PaCE2_train : {pace2_train:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "len_test_t = torch.tensor(lengths_test, dtype=torch.long).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_reg_test, logits_test = model(X_test_t, len_test_t)\n",
    "    probs_test = torch.sigmoid(logits_test).cpu().numpy()\n",
    "\n",
    "y_true_test = np.asarray(y_test)\n",
    "\n",
    "auc_test   = roc_auc_score(y_true_test, probs_test)\n",
    "ece_test   = compute_ece(y_true_test, probs_test)\n",
    "pace2_test = compute_pace(y_true_test, probs_test, L=2)\n",
    "\n",
    "print(\"\\n=== Test Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_test   : {auc_test:.4f}\")\n",
    "print(f\"ECE_test   : {ece_test:.4f}\")\n",
    "print(f\"PaCE2_test : {pace2_test:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "model_tag = f\"lstm_dual_receiving_{STAT_COL.lower()}_line_{LINE_VALUE:.1f}_past{N_PAST_GAMES}_hid{HIDDEN_SIZE}\"\n",
    "\n",
    "model_path   = os.path.join(\"models\",  model_tag + \".pt\")\n",
    "metrics_path = os.path.join(\"metrics\", model_tag + \"_metrics.json\")\n",
    "\n",
    "model_cpu = model.to(\"cpu\")\n",
    "torch.save(model_cpu.state_dict(), model_path)\n",
    "print(f\"Saved model to {model_path}\")\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"STAT_COL\": STAT_COL,\n",
    "    \"line_value\": LINE_VALUE,\n",
    "    \"n_past_games\": N_PAST_GAMES,\n",
    "    \"hidden_size\": HIDDEN_SIZE,\n",
    "    \"train_cfg\": {\n",
    "        \"n_epochs\": cfg.n_epochs,\n",
    "        \"batch_size\": cfg.batch_size,\n",
    "        \"lr\": cfg.lr,\n",
    "        \"device\": cfg.device,\n",
    "    },\n",
    "    \"train_history\": history,  # per-epoch losses\n",
    "    \"train_metrics\": {\n",
    "        \"auc\": float(auc_train),\n",
    "        \"ece\": float(ece_train),\n",
    "        \"pace2\": float(pace2_train),\n",
    "        \"n_train\": int(len(y_true_train)),\n",
    "    },\n",
    "    \"test_metrics\": {\n",
    "        \"auc\": float(auc_test),\n",
    "        \"ece\": float(ece_test),\n",
    "        \"pace2\": float(pace2_test),\n",
    "        \"n_test\": int(len(y_true_test)),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "\n",
    "print(f\"Saved metrics to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM TEST for single leg probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player: George Kittle\n",
      "Prop: YDS over 80\n",
      "Predicted probability (model): 0.018\n"
     ]
    }
   ],
   "source": [
    "player_name = \"George Kittle\"\n",
    "\n",
    "prob = predict_player_over_prob(\n",
    "    model=model,\n",
    "    df=test_df,              \n",
    "    player_name=player_name,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    ")\n",
    "\n",
    "print(f\"Player: {player_name}\")\n",
    "print(f\"Prop: {STAT_COL} over {LINE_VALUE}\")\n",
    "print(f\"Predicted probability (model): {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM TEST for multi leg probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yard_type = \"Receiving\" \n",
    "\n",
    "train_df, test_df, full_df = load_data(yard_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parlay_legs = [\n",
    "    {\n",
    "        \"player\": \"George Kittle\",\n",
    "        \"stat_col\": \"YDS\",\n",
    "        \"line_value\": 55.5,\n",
    "    },\n",
    "    {\n",
    "        \"player\": \"Brandon Aiyuk\",\n",
    "        \"stat_col\": \"YDS\",\n",
    "        \"line_value\": 60.5,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parlay model family: LSTM\n",
      "Leg: George Kittle – YDS > 55.5 → P(hit) = 0.156\n",
      "Leg: Brandon Aiyuk – YDS > 60.5 → P(hit) = 0.448\n",
      "\n",
      "P(all legs hit) = 0.070\n"
     ]
    }
   ],
   "source": [
    "parlay_model_choice = \"LSTM\"  # or \"TFT\" or \"XGBoost\"\n",
    "\n",
    "parlay_prob, leg_probs = compute_parlay_prob(\n",
    "    parlay_legs=parlay_legs,\n",
    "    yard_type=yard_type,\n",
    "    parlay_model_choice=parlay_model_choice,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    full_df=full_df,\n",
    ")\n",
    "\n",
    "print(f\"\\nParlay model family: {parlay_model_choice}\")\n",
    "for leg, p in leg_probs:\n",
    "    print(\n",
    "        f\"Leg: {leg['player']} – {leg['stat_col']} > {leg['line_value']} \"\n",
    "        f\"→ P(hit) = {p:.3f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nP(all legs hit) = {parlay_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFT TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/stock-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TFT] Epoch 01 | Train BCE loss: 0.2693\n",
      "[TFT] Epoch 02 | Train BCE loss: 0.2530\n",
      "[TFT] Epoch 03 | Train BCE loss: 0.2513\n",
      "[TFT] Epoch 04 | Train BCE loss: 0.2495\n",
      "[TFT] Epoch 05 | Train BCE loss: 0.2486\n",
      "[TFT] Epoch 06 | Train BCE loss: 0.2489\n",
      "[TFT] Epoch 07 | Train BCE loss: 0.2467\n",
      "[TFT] Epoch 08 | Train BCE loss: 0.2470\n",
      "[TFT] Epoch 09 | Train BCE loss: 0.2475\n",
      "[TFT] Epoch 10 | Train BCE loss: 0.2476\n",
      "\n",
      "=== TFT Train Metrics (Single-Leg + Parlay) ===\n",
      "AUC_train   : 0.8315\n",
      "ECE_train   : 0.0299\n",
      "PaCE2_train : 0.0201  (random 2-leg parlays)\n",
      "\n",
      "=== TFT Test Metrics (Single-Leg + Parlay) ===\n",
      "AUC_test   : 0.8075\n",
      "ECE_test   : 0.0315\n",
      "PaCE2_test : 0.0267  (random 2-leg parlays)\n",
      "Saved TFT model to models/tft_dual_receiving_yds_line_80.0_past5_dmodel128.pt\n",
      "Saved TFT metrics to metrics/tft_dual_receiving_yds_line_80.0_past5_dmodel128_metrics.json\n"
     ]
    }
   ],
   "source": [
    "train_df_labeled = add_over_under_label(\n",
    "    df=train_df,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    new_col=\"over_label\",\n",
    ")\n",
    "\n",
    "test_df_labeled = add_over_under_label(\n",
    "    df=test_df,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    new_col=\"over_label\",\n",
    ")\n",
    "\n",
    "# 2) Build sequences using that label\n",
    "X_train, y_train, lengths_train, meta_train = prepare_receiving_sequences(\n",
    "    train_df_labeled,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "X_test, y_test, lengths_test, meta_test = prepare_receiving_sequences(\n",
    "    test_df_labeled,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "# 3) Train TFT classifier\n",
    "cfg = TrainConfig(\n",
    "    n_epochs=10,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    device=\"auto\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_result = train_tft_classifier(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    lengths=lengths_train,\n",
    "    d_model=D_MODEL,\n",
    "    n_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.1,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "model   = train_result[\"model\"]\n",
    "history = train_result[\"history\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 4) Train metrics\n",
    "X_train_t  = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "len_train_t = torch.tensor(lengths_train, dtype=torch.long).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_reg_train, logits_train = model(X_train_t, len_train_t)\n",
    "    probs_train = torch.sigmoid(logits_train).cpu().numpy()\n",
    "\n",
    "y_true_train = np.asarray(y_train)\n",
    "\n",
    "auc_train   = roc_auc_score(y_true_train, probs_train)\n",
    "ece_train   = compute_ece(y_true_train, probs_train)\n",
    "pace2_train = compute_pace(y_true_train, probs_train, L=2)\n",
    "\n",
    "print(\"\\n=== TFT Train Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_train   : {auc_train:.4f}\")\n",
    "print(f\"ECE_train   : {ece_train:.4f}\")\n",
    "print(f\"PaCE2_train : {pace2_train:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "# 5) Test metrics\n",
    "X_test_t   = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "len_test_t = torch.tensor(lengths_test, dtype=torch.long).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_reg_test, logits_test = model(X_test_t, len_test_t)\n",
    "    probs_test = torch.sigmoid(logits_test).cpu().numpy()\n",
    "\n",
    "y_true_test = np.asarray(y_test)\n",
    "\n",
    "auc_test   = roc_auc_score(y_true_test, probs_test)\n",
    "ece_test   = compute_ece(y_true_test, probs_test)\n",
    "pace2_test = compute_pace(y_true_test, probs_test, L=2)\n",
    "\n",
    "print(\"\\n=== TFT Test Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_test   : {auc_test:.4f}\")\n",
    "print(f\"ECE_test   : {ece_test:.4f}\")\n",
    "print(f\"PaCE2_test : {pace2_test:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "# 6) Save model + metrics\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "model_tag   = f\"tft_dual_receiving_{STAT_COL.lower()}_line_{LINE_VALUE:.1f}_past{N_PAST_GAMES}_dmodel{D_MODEL}\"\n",
    "model_path  = os.path.join(\"models\",  model_tag + \".pt\")\n",
    "metrics_path = os.path.join(\"metrics\", model_tag + \"_metrics.json\")\n",
    "\n",
    "model_cpu = model.to(\"cpu\")\n",
    "torch.save(model_cpu.state_dict(), model_path)\n",
    "print(f\"Saved TFT model to {model_path}\")\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"stat_col\": STAT_COL,\n",
    "    \"line_value\": LINE_VALUE,\n",
    "    \"n_past_games\": N_PAST_GAMES,\n",
    "    \"d_model\": D_MODEL,\n",
    "    \"train_cfg\": {\n",
    "        \"n_epochs\": cfg.n_epochs,\n",
    "        \"batch_size\": cfg.batch_size,\n",
    "        \"lr\": cfg.lr,\n",
    "        \"device\": cfg.device,\n",
    "    },\n",
    "    \"train_history\": history,\n",
    "    \"train_metrics\": {\n",
    "        \"auc\": float(auc_train),\n",
    "        \"ece\": float(ece_train),\n",
    "        \"pace2\": float(pace2_train),\n",
    "        \"n_train\": int(len(y_true_train)),\n",
    "    },\n",
    "    \"test_metrics\": {\n",
    "        \"auc\": float(auc_test),\n",
    "        \"ece\": float(ece_test),\n",
    "        \"pace2\": float(pace2_test),\n",
    "        \"n_test\": int(len(y_true_test)),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "\n",
    "print(f\"Saved TFT metrics to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFT TEST for single leg probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TFT] Player: George Kittle\n",
      "Prop: YDS over 80\n",
      "Predicted probability (model): 0.067\n"
     ]
    }
   ],
   "source": [
    "player_name = \"George Kittle\"\n",
    "\n",
    "prob = predict_player_over_prob(\n",
    "    model=model,\n",
    "    df=test_df,\n",
    "    player_name=player_name,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    model_type=\"tft\"\n",
    ")\n",
    "\n",
    "print(f\"\\n[TFT] Player: {player_name}\")\n",
    "print(f\"Prop: {STAT_COL} over {LINE_VALUE}\")\n",
    "print(f\"Predicted probability (model): {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFT TEST for multi leg probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yard_type = \"Receiving\" \n",
    "\n",
    "train_df, test_df, full_df = load_data(yard_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parlay_legs = [\n",
    "    {\n",
    "        \"player\": \"George Kittle\",\n",
    "        \"STAT_COL\": \"YDS\",\n",
    "        \"line_value\": 55.5,\n",
    "    },\n",
    "    {\n",
    "        \"player\": \"Brandon Aiyuk\",\n",
    "        \"STAT_COL\": \"YDS\",\n",
    "        \"line_value\": 60.5,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stat_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m parlay_model_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFT\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# or \"TFT\" or \"XGBoost\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m parlay_prob, leg_probs \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_parlay_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparlay_legs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparlay_legs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43myard_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myard_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparlay_model_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparlay_model_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mParlay model family: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparlay_model_choice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leg, p \u001b[38;5;129;01min\u001b[39;00m leg_probs:\n",
      "File \u001b[0;32m~/Desktop/SportsBetting_NN/core_logic.py:159\u001b[0m, in \u001b[0;36mcompute_parlay_prob\u001b[0;34m(parlay_legs, yard_type, parlay_model_choice, train_df, test_df, full_df)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m leg \u001b[38;5;129;01min\u001b[39;00m parlay_legs:\n\u001b[1;32m    158\u001b[0m     player \u001b[38;5;241m=\u001b[39m leg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 159\u001b[0m     stat_col \u001b[38;5;241m=\u001b[39m \u001b[43mleg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstat_col\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m     line_value \u001b[38;5;241m=\u001b[39m leg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    162\u001b[0m     prop_key \u001b[38;5;241m=\u001b[39m (stat_col, line_value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stat_col'"
     ]
    }
   ],
   "source": [
    "parlay_model_choice = \"TFT\" \n",
    "\n",
    "parlay_prob, leg_probs = compute_parlay_prob(\n",
    "    parlay_legs=parlay_legs,\n",
    "    yard_type=yard_type,\n",
    "    parlay_model_choice=parlay_model_choice,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    full_df=full_df,\n",
    ")\n",
    "\n",
    "print(f\"\\nParlay model family: {parlay_model_choice}\")\n",
    "for leg, p in leg_probs:\n",
    "    print(\n",
    "        f\"Leg: {leg['player']} – {leg['STAT_COL']} > {leg['line_value']} \"\n",
    "        f\"→ P(hit) = {p:.3f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nP(all legs hit) = {parlay_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/stock-env/lib/python3.10/site-packages/xgboost/training.py:199: UserWarning: [01:35:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGB Train Metrics (Single-Leg + Parlay) ===\n",
      "AUC_train   : 0.9147\n",
      "ECE_train   : 0.0334\n",
      "PaCE2_train : 0.0157  (random 2-leg parlays)\n",
      "\n",
      "=== XGB Test Metrics (Single-Leg + Parlay) ===\n",
      "AUC_test   : 0.8090\n",
      "ECE_test   : 0.0094\n",
      "PaCE2_test : 0.0170  (random 2-leg parlays)\n",
      "Saved XGB model to models/xgb_dual_receiving_yds_line_80.0_past5.json\n",
      "Saved XGB metrics to metrics/xgb_dual_receiving_yds_line_80.0_past5_metrics.json\n"
     ]
    }
   ],
   "source": [
    "train_df_labeled = add_over_under_label(\n",
    "    df=train_df,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    new_col=\"over_label\",\n",
    ")\n",
    "\n",
    "test_df_labeled = add_over_under_label(\n",
    "    df=test_df,\n",
    "    stat_col=STAT_COL,\n",
    "    line_value=LINE_VALUE,\n",
    "    new_col=\"over_label\",\n",
    ")\n",
    "\n",
    "X_train, y_train, lengths_train, meta_train = prepare_receiving_sequences(\n",
    "    train_df_labeled,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "X_test, y_test, lengths_test, meta_test = prepare_receiving_sequences(\n",
    "    test_df_labeled,\n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    target_col=\"over_label\",\n",
    ")\n",
    "\n",
    "\n",
    "xgb_cfg = XGBTrainConfig(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "xgb_result = train_xgb_classifier(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    lengths=lengths_train,\n",
    "    cfg=xgb_cfg,\n",
    ")\n",
    "\n",
    "xgb_model   = xgb_result[\"model\"]\n",
    "xgb_history = xgb_result[\"history\"]\n",
    "\n",
    "\n",
    "X_train_flat = flatten_sequences(X_train)\n",
    "\n",
    "y_train_np = np.asarray(y_train, dtype=float)\n",
    "train_probs = xgb_model.predict_proba(X_train_flat)[:, 1]\n",
    "\n",
    "auc_train   = roc_auc_score(y_train_np, train_probs)\n",
    "ece_train   = compute_ece(y_train_np, train_probs)\n",
    "pace2_train = compute_pace(y_train_np, train_probs, L=2)\n",
    "\n",
    "print(\"\\n=== XGB Train Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_train   : {auc_train:.4f}\")\n",
    "print(f\"ECE_train   : {ece_train:.4f}\")\n",
    "print(f\"PaCE2_train : {pace2_train:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# 5. TEST METRICS\n",
    "# =======================================================\n",
    "X_test_flat = flatten_sequences(X_test)\n",
    "\n",
    "y_test_np = np.asarray(y_test, dtype=float)\n",
    "test_probs = xgb_model.predict_proba(X_test_flat)[:, 1]\n",
    "\n",
    "auc_test   = roc_auc_score(y_test_np, test_probs)\n",
    "ece_test   = compute_ece(y_test_np, test_probs)\n",
    "pace2_test = compute_pace(y_test_np, test_probs, L=2)\n",
    "\n",
    "print(\"\\n=== XGB Test Metrics (Single-Leg + Parlay) ===\")\n",
    "print(f\"AUC_test   : {auc_test:.4f}\")\n",
    "print(f\"ECE_test   : {ece_test:.4f}\")\n",
    "print(f\"PaCE2_test : {pace2_test:.4f}  (random 2-leg parlays)\")\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# 6. SAVE MODEL + METRICS\n",
    "# =======================================================\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "model_tag = f\"xgb_dual_receiving_{STAT_COL.lower()}_line_{LINE_VALUE:.1f}_past{N_PAST_GAMES}\"\n",
    "\n",
    "model_path   = os.path.join(\"models\",  model_tag + \".json\")\n",
    "metrics_path = os.path.join(\"metrics\", model_tag + \"_metrics.json\")\n",
    "\n",
    "xgb_model.save_model(model_path)\n",
    "print(f\"Saved XGB model to {model_path}\")\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"stat_col\": STAT_COL,\n",
    "    \"line_value\": LINE_VALUE,\n",
    "    \"n_past_games\": N_PAST_GAMES,\n",
    "\n",
    "    \"xgb_cfg\": {\n",
    "        \"n_estimators\": xgb_cfg.n_estimators,\n",
    "        \"max_depth\": xgb_cfg.max_depth,\n",
    "        \"learning_rate\": xgb_cfg.learning_rate,\n",
    "        \"subsample\": xgb_cfg.subsample,\n",
    "        \"colsample_bytree\": xgb_cfg.colsample_bytree,\n",
    "        \"reg_lambda\": xgb_cfg.reg_lambda,\n",
    "        \"reg_alpha\": xgb_cfg.reg_alpha,\n",
    "        \"eval_metric\": xgb_cfg.eval_metric,\n",
    "    },\n",
    "\n",
    "    \"train_history\": xgb_history,\n",
    "\n",
    "    \"train_metrics\": {\n",
    "        \"auc\": float(auc_train),\n",
    "        \"ece\": float(ece_train),\n",
    "        \"pace2\": float(pace2_train),\n",
    "        \"n_train\": int(len(y_train_np)),\n",
    "    },\n",
    "\n",
    "    \"test_metrics\": {\n",
    "        \"auc\": float(auc_test),\n",
    "        \"ece\": float(ece_test),\n",
    "        \"pace2\": float(pace2_test),\n",
    "        \"n_test\": int(len(y_test_np)),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2)\n",
    "\n",
    "print(f\"Saved XGB metrics to {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] Player: Amon-Ra St. Brown\n",
      "Prop: YDS over 80\n",
      "Predicted probability (model): 0.409\n"
     ]
    }
   ],
   "source": [
    "player_name = \"Amon-Ra St. Brown\"\n",
    "\n",
    "prob_xgb = predict_player_over_prob(\n",
    "    model=xgb_model,\n",
    "    df=test_df,\n",
    "    player_name=player_name,\n",
    "    stat_col=STAT_COL,       \n",
    "    line_value=LINE_VALUE,    \n",
    "    n_past_games=N_PAST_GAMES,\n",
    "    model_type=\"xgboost\",   \n",
    ")\n",
    "\n",
    "print(f\"[XGBoost] Player: {player_name}\")\n",
    "print(f\"Prop: {STAT_COL} over {LINE_VALUE}\")\n",
    "print(f\"Predicted probability (model): {prob_xgb:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB TEST for multi leg probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yard_type = \"Receiving\" \n",
    "\n",
    "train_df, test_df, full_df = load_data(yard_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parlay_legs = [\n",
    "    {\n",
    "        \"player\": \"George Kittle\",\n",
    "        \"stat_col\": \"YDS\",\n",
    "        \"line_value\": 55.5,\n",
    "    },\n",
    "    {\n",
    "        \"player\": \"Brandon Aiyuk\",\n",
    "        \"stat_col\": \"YDS\",\n",
    "        \"line_value\": 60.5,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parlay model family: XGBoost\n",
      "Leg: George Kittle – YDS > 55.5 → P(hit) = 0.090\n",
      "Leg: Brandon Aiyuk – YDS > 60.5 → P(hit) = 0.497\n",
      "\n",
      "P(all legs hit) = 0.045\n"
     ]
    }
   ],
   "source": [
    "parlay_model_choice = \"XGBoost\" \n",
    "\n",
    "parlay_prob, leg_probs = compute_parlay_prob(\n",
    "    parlay_legs=parlay_legs,\n",
    "    yard_type=yard_type,\n",
    "    parlay_model_choice=parlay_model_choice,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    full_df=full_df,\n",
    ")\n",
    "\n",
    "print(f\"\\nParlay model family: {parlay_model_choice}\")\n",
    "for leg, p in leg_probs:\n",
    "    print(\n",
    "        f\"Leg: {leg['player']} – {leg['stat_col']} > {leg['line_value']} \"\n",
    "        f\"→ P(hit) = {p:.3f}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nP(all legs hit) = {parlay_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
